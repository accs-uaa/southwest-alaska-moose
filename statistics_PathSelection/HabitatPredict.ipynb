{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abundance Predict\n",
    "\n",
    "**Written by Timm Nawrocki**\n",
    "\n",
    "*Last updated Monday March 29, 2021.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ---------------------------------------------------------------------------\n",
    "# Predict Vegetation Abundance\n",
    "# Author: Timm Nawrocki, Alaska Center for Conservation Science\n",
    "# Created on: 2021-03-29\n",
    "# Usage: Must be executed as a Jupyter Notebook in an Anaconda 3 installation.\n",
    "# Description: \"Predict Vegetation Abundance\" applies the trained classifier and regressor to data in regular point grid\n",
    "# format stored in csv files to create a composite prediction representing the distribution and proportional abundance of the\n",
    "# target species.\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set root directory\n",
    "root_folder = 'N:/ACCS_Work/Projects/WildlifeEcology/Moose_SouthwestAlaska/Data/Data_Output'\n",
    "# Define calf status\n",
    "map_group = 'Calf_RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid folder\n",
    "grid_folder = os.path.join(root_folder,\n",
    "                           'extracted_grids')\n",
    "# Define model folder\n",
    "model_folder = os.path.join(root_folder,\n",
    "                           'model_results',\n",
    "                           map_group)\n",
    "# Define prediction folder\n",
    "prediction_folder = os.path.join(root_folder,\n",
    "                                'predicted_tables',\n",
    "                                map_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make output directory if it does not already exist\n",
    "if os.path.exists(prediction_folder) == 0:\n",
    "    os.mkdir(prediction_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable sets\n",
    "predictor_all = ['elevation_mean', 'roughness_mean', 'forest_edge_mean', 'tundra_edge_mean', 'alnus_mean', 'betshr_mean',\n",
    "                 'dectre_mean', 'erivag_mean', 'picgla_mean', 'picmar_mean', 'salshr_mean', 'wetsed_mean']\n",
    "coordinates = ['x', 'y']\n",
    "absence = ['absence']\n",
    "presence = ['presence']\n",
    "prediction = ['prediction']\n",
    "selection = ['selection']\n",
    "output_columns = coordinates + selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for file manipulation, data manipulation, and plotting\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import Random Forest implementation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Import joblib\n",
    "import joblib\n",
    "# Import timing packages\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to read threshold values from text file\n",
    "def readThreshold(inFile):\n",
    "    threshold_reader = open(inFile, \"r\")\n",
    "    threshold = threshold_reader.readlines()\n",
    "    threshold_reader.close()\n",
    "    outThreshold = float(threshold[0])\n",
    "    return outThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to composite model results\n",
    "def compositeSelection(input_data, presence, threshold, output):\n",
    "    # Determine positive and negative ranges\n",
    "    positive_range = input_data[presence[0]].max() - threshold\n",
    "    negative_range = threshold - input_data[presence[0]].min()\n",
    "    # Define a function to threshold presences and absences and standardize values from -1 (avoidance) to 1 (selection)\n",
    "    def compositeRows(row):\n",
    "        if row[presence[0]] == threshold:\n",
    "            return 0\n",
    "        elif row[presence[0]] > threshold:\n",
    "            adjusted_value = (row[presence[0]] - threshold) / positive_range\n",
    "            return adjusted_value\n",
    "        elif row[presence[0]] < threshold:\n",
    "            adjusted_value = (row[presence[0]] - threshold) / negative_range\n",
    "            return adjusted_value\n",
    "    # Apply function to all rows in data\n",
    "    input_data[output[0]] = input_data.apply(lambda row: compositeRows(row), axis=1)\n",
    "    # Return the data frame with composited results\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the trained model\n",
    "classifier = joblib.load(os.path.join(model_folder, 'classifier.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read thresholds from text files in the workspace folder and store as variables\n",
    "threshold = readThreshold(os.path.join(model_folder, 'threshold.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of input files for the prediction step\n",
    "os.chdir(grid_folder)\n",
    "grid_files = glob.glob('*.csv')\n",
    "grid_length = len(grid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting grid 1 of 744...\n",
      "\tLoading grid data into memory...\n",
      "\tCompleted at 2021-03-29 21:28 (Elapsed time: 0:00:01)\n",
      "\t----------\n",
      "\tClassifying presence-absence...\n",
      "\tCompleted at 2021-03-29 21:28 (Elapsed time: 0:00:24)\n",
      "\t----------\n",
      "\tExporting results...\n",
      "\tCompleted at 2021-03-29 21:29 (Elapsed time: 0:00:14)\n",
      "\t----------\n",
      "Iteration completed at 2021-03-29 21:29 (Elapsed time: 0:00:41)\n",
      "----------\n",
      "Predicting grid 2 of 744...\n",
      "\tLoading grid data into memory...\n",
      "\tCompleted at 2021-03-29 21:29 (Elapsed time: 0:00:01)\n",
      "\t----------\n",
      "\tClassifying presence-absence...\n",
      "\tCompleted at 2021-03-29 21:29 (Elapsed time: 0:00:26)\n",
      "\t----------\n",
      "\tExporting results...\n",
      "\tCompleted at 2021-03-29 21:29 (Elapsed time: 0:00:15)\n",
      "\t----------\n",
      "Iteration completed at 2021-03-29 21:29 (Elapsed time: 0:00:43)\n",
      "----------\n",
      "Predicting grid 3 of 744...\n",
      "\tLoading grid data into memory...\n",
      "\tCompleted at 2021-03-29 21:29 (Elapsed time: 0:00:01)\n",
      "\t----------\n",
      "\tClassifying presence-absence...\n",
      "\tCompleted at 2021-03-29 21:30 (Elapsed time: 0:00:24)\n",
      "\t----------\n",
      "\tExporting results...\n",
      "\tCompleted at 2021-03-29 21:30 (Elapsed time: 0:00:14)\n",
      "\t----------\n",
      "Iteration completed at 2021-03-29 21:30 (Elapsed time: 0:00:41)\n",
      "----------\n",
      "Predicting grid 4 of 744...\n",
      "\tLoading grid data into memory...\n",
      "\tCompleted at 2021-03-29 21:30 (Elapsed time: 0:00:01)\n",
      "\t----------\n",
      "\tClassifying presence-absence...\n",
      "\tCompleted at 2021-03-29 21:30 (Elapsed time: 0:00:25)\n",
      "\t----------\n",
      "\tExporting results...\n",
      "\tCompleted at 2021-03-29 21:31 (Elapsed time: 0:00:15)\n",
      "\t----------\n",
      "Iteration completed at 2021-03-29 21:31 (Elapsed time: 0:00:42)\n",
      "----------\n",
      "Predicting grid 5 of 744...\n",
      "\tLoading grid data into memory...\n",
      "\tCompleted at 2021-03-29 21:31 (Elapsed time: 0:00:01)\n",
      "\t----------\n",
      "\tClassifying presence-absence...\n"
     ]
    }
   ],
   "source": [
    "# Loop through the prediction function for all input files\n",
    "count = 1\n",
    "for grid in grid_files:\n",
    "    # Define the output csv file\n",
    "    output_csv = os.path.join(prediction_folder, grid)\n",
    "    \n",
    "    # Predict output table if it does not already exist\n",
    "    if os.path.exists(output_csv) == 0:\n",
    "        total_start = time.time()\n",
    "        print(f'Predicting grid {count} of {grid_length}...')\n",
    "    \n",
    "        # Identify file path to the input csv file\n",
    "        print('\\tLoading grid data into memory...')\n",
    "        iteration_start = time.time()\n",
    "        input_csv = os.path.join(grid_folder, grid)\n",
    "        # Load the input data\n",
    "        input_data = pd.read_csv(input_csv)\n",
    "        input_data = input_data.rename(columns={'elevation': 'elevation_mean',\n",
    "                                               'roughness': 'roughness_mean',\n",
    "                                               'forest_edge': 'forest_edge_mean',\n",
    "                                               'tundra_edge': 'tundra_edge_mean',\n",
    "                                               'alnus': 'alnus_mean',\n",
    "                                               'betshr': 'betshr_mean',\n",
    "                                               'dectre': 'dectre_mean',\n",
    "                                               'erivag': 'erivag_mean',\n",
    "                                               'picgla': 'picgla_mean',\n",
    "                                               'picmar': 'picmar_mean',\n",
    "                                               'salshr': 'salshr_mean',\n",
    "                                               'wetsed': 'wetsed_mean'})\n",
    "        input_data = input_data.dropna(axis=0, how='any')\n",
    "        input_data[predictor_all] = input_data[predictor_all].astype(float)\n",
    "        # Define the X data\n",
    "        X_data = input_data[predictor_all].astype(float)\n",
    "        iteration_end = time.time()\n",
    "        iteration_elapsed = int(iteration_end - iteration_start)\n",
    "        iteration_success_time = datetime.datetime.now()\n",
    "        print(f'\\tCompleted at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "        print('\\t----------')\n",
    "    \n",
    "        # Predict the classifier\n",
    "        print('\\tClassifying presence-absence...')\n",
    "        iteration_start = time.time()\n",
    "        classification = classifier.predict_proba(X_data)\n",
    "        # Concatenate predicted values to input data frame\n",
    "        input_data = input_data.assign(absence = classification[:,0])\n",
    "        input_data = input_data.assign(presence = classification[:,1])\n",
    "        iteration_end = time.time()\n",
    "        iteration_elapsed = int(iteration_end - iteration_start)\n",
    "        iteration_success_time = datetime.datetime.now()\n",
    "        print(f'\\tCompleted at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "        print('\\t----------')\n",
    "    \n",
    "        # Convert to selection\n",
    "        print('\\tExporting results...')\n",
    "        iteration_start = time.time()\n",
    "        input_data = compositeSelection(input_data, presence, threshold, selection)\n",
    "        # Export prediction to csv\n",
    "        output_data = input_data[output_columns]\n",
    "        output_data.to_csv(output_csv, header=True, index=False, sep=',', encoding='utf-8')\n",
    "        iteration_end = time.time()\n",
    "        iteration_elapsed = int(iteration_end - iteration_start)\n",
    "        iteration_success_time = datetime.datetime.now()\n",
    "        print(f'\\tCompleted at {iteration_success_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=iteration_elapsed)})')\n",
    "        print('\\t----------')\n",
    "    \n",
    "        total_end = time.time()\n",
    "        total_elapsed = int(total_end - total_start)\n",
    "        total_success_time = datetime.datetime.now()\n",
    "        print(f'Iteration completed at {total_success_time.strftime(\"%Y-%m-%d %H:%M\")} (Elapsed time: {datetime.timedelta(seconds=total_elapsed)})')\n",
    "        print('----------')\n",
    "    \n",
    "    else:\n",
    "        print(f'Grid {count} of {grid_length} already predicted.')\n",
    "        print('----------')\n",
    "    \n",
    "    # Increase counter\n",
    "    count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
